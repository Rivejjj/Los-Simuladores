{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grupo 4: Aschieri Juan Pablo, Civini Diego Emanuel, Rivero Joaquin, Rovira Rossel Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e, log\n",
    "import time\n",
    "from heapq import heappush, heappop\n",
    "from scipy.stats import poisson\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import simpy\n",
    "import numpy as np\n",
    "import random\n",
    "from statistics import mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generador de numeros aleatorio del TP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xorshift_generator:\n",
    "    def __init__(self, seed):\n",
    "        self.x = seed\n",
    "        self.y = 463820370\n",
    "        self.z = 138409373\n",
    "        self.w = 12872349\n",
    "\n",
    "    def rand(self):\n",
    "        tmp = ( self.x^ (self.x <<13) ) \n",
    "        self.x = self.y\n",
    "        self.y = self.z\n",
    "        self.z = self.w\n",
    "        self.w = (self.w^(self.w>>17) ) ^ (tmp^(tmp>>5))\n",
    "        return self.w & 0xffffffff\n",
    "    \n",
    "    def get_n_rand(self, n):\n",
    "        rand_numbers = []\n",
    "        for i in range(n):\n",
    "            rand_numbers.append(self.rand())\n",
    "        return rand_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Uniform_generator:\n",
    "    def __init__(self, seed, scale= 1, displacement= 0):\n",
    "        self.xorshift_genertor = Xorshift_generator(seed)\n",
    "        self.scale = scale\n",
    "        self.displacement = displacement\n",
    "\n",
    "    def rand(self):\n",
    "        n = self.xorshift_genertor.rand() / ((2**32)-1)\n",
    "        return n * self.scale + self.displacement\n",
    "    \n",
    "    def get_n_rand(self, n):\n",
    "        rand_numbers = []\n",
    "        for i in range(n):\n",
    "            rand_numbers.append(self.rand())\n",
    "        return rand_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp_generator:\n",
    "    def __init__(self, seed, parameter=1):\n",
    "        self.parameter = parameter\n",
    "        self.Uniform_generator = Uniform_generator(seed)\n",
    "\n",
    "    def rand(self):\n",
    "        r = self.Uniform_generator.rand()\n",
    "        if self.parameter >=1:\n",
    "            return log(r/self.parameter) / (-1*self.parameter)\n",
    "        else: \n",
    "            return -log(1 - r) / self.parameter\n",
    "\n",
    "    def get_n_rand(self, n):\n",
    "        rand_numbers = []\n",
    "        for i in range(n):\n",
    "            rand_numbers.append(self.rand())\n",
    "        return rand_numbers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descubri que los primeros dos numeros del generador son muy distintos y despues se acomoda. lo de abajo hay que borrarlo  \n",
    "tambien sospecho que por lo general da media menor que 6 mas seguido que mayor que 6, creo que tienee sentido pero mmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4529455914998052, 2.676836078476345, 16.931406239723316, 2.5928427055844065, 3.8396765840682994, 1.9674026472238866, 3.1243274120090416, 3.6969424005494154, 2.9408806694326635, 7.574070005951264, 5.484340091548873, 3.345898188046458, 23.323926787821396, 8.515700636470296, 1.549858136120757, 4.861197133553371, 9.79892676165755, 3.6443400990095647, 8.229818874488204, 5.183044000922176, 5.837570942519065, 4.4995779038364985, 0.605100405180614, 10.42779347835347, 5.43133263582364, 4.215978243685426, 8.045923238722773, 4.4326229067041, 2.2627843673239334, 0.690454560358275, 0.9655684741059198, 3.1137927294762084, 3.200452864075284, 2.440227027595981, 0.5833390326656334, 2.2801787565786293, 0.16420203947744408, 2.530712091839689, 1.2319944159845069, 2.4204301662178054, 1.8878304157310841, 10.918794708781029, 1.540294098399468, 0.8440336548803655, 6.375936990033535, 2.6343689938566657, 1.9336158809823965, 1.944865983825561, 0.2281728601967421, 1.0675664629958679, 5.905074473088323, 0.16954836265829898, 2.791962319918095, 7.636311701854794, 11.96160475855299, 4.220525246415895, 1.5426574729450924, 5.260522085179732, 1.1260990774977453, 0.4778475379092066, 3.77970140319775, 1.393816495502756, 1.3128837796272592, 2.570004791745505, 9.17154421610102, 7.632012672363202, 2.1302684687837146, 5.404937936548517, 12.162887644501668, 3.7646473482413323, 5.03165312313884, 0.7685001749076622, 1.9049405639230217, 0.5982608610233946, 3.730490753771057, 2.7361976187210013, 2.419563815861553, 2.259041778538338, 5.289356689063643, 0.3778362274073313, 5.418137499244859, 12.3013543675074, 6.3069173828568985, 9.110633120877996, 2.9439525457652715, 11.638631260958224, 13.044465722919648, 1.3959409174607436, 11.451522746649863, 0.3746280006457181, 10.99088840325556, 7.476099464966969, 12.070613537721757, 0.6785493643541122, 0.6285050917531916, 0.04125814967880491, 4.379072631427412, 2.168683546722485, 9.695350237975472, 17.590188264246212]\n",
      "4.697259890303421\n"
     ]
    }
   ],
   "source": [
    "seed = int(time.time())\n",
    "\n",
    "exp_generator = Exp_generator(seed, 1/6)\n",
    "\n",
    "b = exp_generator.rand()\n",
    "b = exp_generator.rand()\n",
    "a = []\n",
    "\n",
    "for i in range(100):\n",
    "    n = exp_generator.rand()\n",
    "    a.append(n)\n",
    "    if n < 0:\n",
    "        print(n)\n",
    "\n",
    "print(a)\n",
    "print(sum(a)/len(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un generador de una distribucion de poisson porque lo utilizaremos mas adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    resultado = 1\n",
    "    for i in range(1, n + 1):\n",
    "        resultado *= i\n",
    "    return resultado\n",
    "\n",
    "def poisson_probability(parameter, i, previous_probability):\n",
    "    if previous_probability == 0:\n",
    "        return poisson.pmf(i, parameter)\n",
    "    return (parameter/i)*previous_probability\n",
    "\n",
    "class Poisson_generator:\n",
    "    def __init__(self, seed, parameter):\n",
    "        self.parameter = parameter\n",
    "        self.Uniform_generator = Uniform_generator(seed)\n",
    "\n",
    "    def rand(self):\n",
    "        r = self.Uniform_generator.rand()\n",
    "\n",
    "        accumulated_probability = poisson_probability(self.parameter, 0, 0)\n",
    "        previous_probability = accumulated_probability\n",
    "        i = 0\n",
    "\n",
    "        while(accumulated_probability < r):\n",
    "            i += 1\n",
    "            previous_probability = poisson_probability(self.parameter, i, previous_probability)\n",
    "            accumulated_probability += previous_probability\n",
    "\n",
    "        return i\n",
    "    \n",
    "    def get_n_rand(self, n):\n",
    "        rand_numbers = []\n",
    "        for i in range(n):\n",
    "            rand_numbers.append(self.rand())\n",
    "        return rand_numbers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumimos que el satÃ©lite da siempre la misma vuelta al mundo que tarda lo mismo, y que se puede pensar al tiempo en que tarda el satelite en llegar a una posicion a la que puede sacar una foto de la request como una uniforme entre 0 y el tiempo en que tarda en dar la vuelta al mundo, ya que los puntos sobre el globo se distribuyen uniformemente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simular el problema lo que hacemos es definir un delta de tiempo (time step), que sera de cada que intervalo discreto avanzaremos el tiempo de la simulacion. Por cada iteracion generamos un valor de una distribucion de poisson que representa la cantidad de arribos de solicitudes que llegaron en el ultimo intervalo de tiempo. Por cada solicitud de tiempo que halla llegado luego generamos un valor de tiempo con una distribucion uniforme entre 0 y el satelite_perior (tiempo en dar la vuelta al mundo del satelite), que representa el tiempo que tardara el satelite en estar en posicion para poder sacar la foto. Por cada iteracion avanzamos el tiempo de todas las request en la cola, y agregamos las nuevas, ademas de ir anotando datos como cuantas veces hubo cada longitud de cola en todas las iteraciones, y cuanto fue el tiempo para servir a la primera request para cada longitud de cola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_satelite_request_queue_length(time_step, iterations, request_per_unit_time, satelite_period):\n",
    "    generator_amount_of_request = Poisson_generator(int(time.time()) * 8647359734, request_per_unit_time*time_step)\n",
    "    generator_time_to_serve = Uniform_generator(int(time.time()) * 345678976, satelite_period)\n",
    "    simulated_queue = []\n",
    "    observed_queue_length = {}\n",
    "    time_to_serve_first_for_queue_length = {}\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        advance_time(simulated_queue, time_step)\n",
    "        get_acumulated_requests(generator_amount_of_request, simulated_queue, generator_time_to_serve)    \n",
    "        observed_queue_length[len(simulated_queue)] = observed_queue_length.get(len(simulated_queue), 0) + 1\n",
    "        if len(simulated_queue) != 0:\n",
    "            time_to_serve_first_for_queue_length.setdefault(len(simulated_queue), []).append(simulated_queue[0])\n",
    "            \n",
    "    return get_frequencies(observed_queue_length, iterations), get_mean_times(time_to_serve_first_for_queue_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advance_time(simulated_queue, time_step):\n",
    "    for i in range(len(simulated_queue)):\n",
    "        simulated_queue[i] -= time_step\n",
    "\n",
    "    while (len(simulated_queue) != 0 and simulated_queue[0] <= 0):\n",
    "        item = heappop(simulated_queue)\n",
    "        #print(f'Se elimino una request de tiempo: {item}')\n",
    "\n",
    "def get_acumulated_requests(generator_amount_of_request, simulated_queue, generator_time_to_serve):\n",
    "    amount_of_requests = generator_amount_of_request.rand()\n",
    "    for request in range(amount_of_requests):\n",
    "        #por ahora asumimos que el time to serve es uniforme, porque se hacen requests uniformemente alrededor del mundo\n",
    "        heappush(simulated_queue, generator_time_to_serve.rand())\n",
    "\n",
    "def get_frequencies(observed_queue_length, iterations):\n",
    "    #print(f'Entro a get_frequencies con dicc = {observed_queue_length}')\n",
    "    observed_frequencies = []\n",
    "    #print(f'El maximo es: {max(observed_queue_length.keys())}')\n",
    "    for j in range(max(observed_queue_length.keys()) + 1):\n",
    "        times_observed = observed_queue_length.get(j, 0)\n",
    "        #print(f'Para {j} se observo {times_observed}')\n",
    "        observed_frequencies.append(times_observed/iterations)\n",
    "    return observed_frequencies\n",
    "\n",
    "def get_mean_times(time_to_serve_for_queue_length):\n",
    "    mean_times = {}\n",
    "\n",
    "    for key in time_to_serve_for_queue_length:\n",
    "        sum_of_times = 0\n",
    "        for j in time_to_serve_for_queue_length[key]:\n",
    "            sum_of_times += j\n",
    "        mean_times[key] = sum_of_times/len(time_to_serve_for_queue_length[key])\n",
    "    \n",
    "    return mean_times"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulamos un ejemplo donde tomamos que el satelite tarde 48 horas en dar la vuelta al mundo, y que llegan 10 requests por dia en promedio. Usamos un intervalo de media hora y realizamos 50 000 horas de simulacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies, times = simulate_satelite_request_queue_length(0.5, 100000, 5/12, 48)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que como en general se acumulan las request hasta llegar al rededor de 10 y luego tiende a disminuir la cantidad que hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = list(range(len(frequencies)))\n",
    "y_axis = frequencies\n",
    "plt.plot(x_axis, y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paper llegaba a la conclusion de que cuantas mas solicitudes hayan en la cola, el tiempo que se tarda en servir estas request es menor. Para verificar esto miramos el siguiente grafico que muestra el tiempo promedio que tarda el satelite en servir al request mas cercano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(times.keys(), times.values())\n",
    "plt.xlabel(\"Queue length\")\n",
    "plt.ylabel(\"Avarege time to serve first request\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso asi sucede, cuantas mas solicitudes hay en la cola menor es el tiempo para tomar la foto. Esto tiene sentido ya que cuantas mas request hayan en espera mas chances habra de que haya alguna mas cercana.\n",
    "Si bien el grafico solo muestra la primera requet, como esto se modela como un proceso de poisson, por propiedad de perdidad de memoria se puede ver que se cumplira para el tiempo entre todos los arribos. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100\n",
    "SIM_TIME = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Factor de ocupaciÃ³n del sistema. (listo)\n",
    "- Cantidad media de solicitudes en el buffer (listo)\n",
    "- Cantidad media de solicitudes en el sistema (listo)\n",
    "- Tiempo medio que las solicitudes estÃ¡n en el buffer (listo)\n",
    "- Tiempo medio de solicitudes en el sistema (listo)\n",
    "- Determinar el tamaÃ±a del buffer para que la probabilidad de que haya lugar para recibir solicitudes sea\n",
    "como mucho 3%.\n",
    "- Evaluar la posibilidad de reemplazar las dos mÃ¡quinas por una sola que procesa todos las solicitudes en\n",
    "un tiempo fijo de 5 segundos. Si el costo de tener solicitudes en el buffer es 0,2 USD/minuto y el costo\n",
    "de modificar la mÃ¡quina es 2000 USD, CuÃ¡nto tiempo tomarÃ¡ amortizar el inversiÃ³n?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera cada maquina es un proceso y desp hay otro proceso que se encarga de llenar las lista con requests para que cada maquina vaya desencolando \n",
    "y procesando requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    \n",
    "    def __init__(self,id):\n",
    "        self.working_time = 0\n",
    "        self.requests_taken = 0\n",
    "        self.id = id\n",
    "        self.req_time_stats = []\n",
    "    \n",
    "    def process_request(self, request):\n",
    "        self.requests_taken += 1\n",
    "        self.working_time += request\n",
    "\n",
    "    def add_req_time_stat(self, time_tup):\n",
    "        # The tuple has the following format: (req_buffer_time, req_system_time, req_finish_time)\n",
    "        self.req_time_stats.append(time_tup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Request:\n",
    "    def __init__(self, arrival_time):\n",
    "        self.arrival_time = arrival_time\n",
    "        self.time_at_buffer = 0\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Con esta implementacion, las maquinas chequean que haya requests en la cola cada 1 seg. Osea, que si la cola estaa vacia, la maquina cada 1 seg va a \n",
    "chequear si llego un nuevo mensaje. Ver con los chicos si estan de acuerdo con esto (o tamb preguntar al de la practica). Porque otro caso que CREO que se puede\n",
    "hacer es que apenas llegue un request, la maquina ya sepa y lo empieze a procesar all instante.\n",
    "Tambien ver que onda el arrribo de mensajes, estan llegando cada mucho tiempo y los procesa re rapido entonces la cola siempre esta vacia\n",
    "\"\"\"\n",
    "def request_generator(env, requests_center, requests_buffer, seed):\n",
    "    \"\"\"Las solicitudes llegan siguiendo un proceso Poisson con una frecuencia media de 10\n",
    "    por minuto. Por ende el tiempo entre 2 solicitudes consecutivas seguira una distribucion\n",
    "    Exponencial de paremtro 10.\"\"\"\n",
    "    exponential_gen = Exp_generator(seed, 1/6) \n",
    "    \n",
    "    print(\"Requests start to arrive\")\n",
    "    for i in itertools.count():\n",
    "        time_for_next_request = exponential_gen.rand()\n",
    "        #time_for_next_request = np.random.exponential(6) # El parametro en esta lib tiene que ser b=1/lambda\n",
    "\n",
    "        print(f\"The next request will arrive in {time_for_next_request}, we are at {env.now}\")\n",
    "        yield env.timeout(time_for_next_request)\n",
    "        with requests_center.request() as req:\n",
    "            yield req\n",
    "            if len(requests_buffer.items) == BUFFER_SIZE:\n",
    "                print(f\"The buffer is full and cannot accept more requests. This requests has been dropped at time {env.now}\")\n",
    "            else:\n",
    "                print(f\"A request arrived and was buffered at time {env.now}\")\n",
    "                yield requests_buffer.put(env.now)\n",
    "    print(\"Requests will stop to arrive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_machine(env, requests_center, requests_buffer, seed, machine):\n",
    "    exponential_gen = Exp_generator(seed, 1/10)\n",
    "    print(f\"The machine {machine.id} starts.\")\n",
    "    while True:\n",
    "        \n",
    "        time_to_process = 0.001\n",
    "        request_processed = False\n",
    "        #print(f\"Machine {machine.id} will try to process a request at {env.now}\")\n",
    "        with requests_center.request() as req:\n",
    "            yield req\n",
    "            \n",
    "            if len(requests_buffer.items) != 0:\n",
    "                print(f\"A request is starting to be processed by machine {machine.id} at {env.now}\")\n",
    "                arrival_time = yield requests_buffer.get()\n",
    "                print(arrival_time)\n",
    "                buffer_time = env.now - arrival_time\n",
    "                print(f\"La cantidad de requests en el buffer es {len(requests_buffer.items)}\")\n",
    "                time_to_process = exponential_gen.rand()\n",
    "                #time_to_process = np.random.exponential(10)\n",
    "                machine.process_request(time_to_process)\n",
    "                print(f\"Machine {machine.id} will finish at {time_to_process + env.now}\")\n",
    "                request_processed = True\n",
    "                \n",
    "        # If there are no requests to process in the buffer, the timeout is of 0 seconds.\n",
    "        yield env.timeout(time_to_process)\n",
    "        if request_processed:\n",
    "            system_time = env.now - arrival_time\n",
    "            finish_time = arrival_time + system_time\n",
    "            time_tup = (buffer_time, system_time, finish_time)\n",
    "            machine.add_req_time_stat(time_tup)\n",
    "            print(f\"Machine {machine.id} has finished processing the request at {env.now}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_stats(env, buffer, amount):\n",
    "    while True:\n",
    "        amount.append(len(buffer.items))\n",
    "        yield env.timeout(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos usar nuestro generador, ronda cantidad de llegadas 11/12 en el primer minuto (empiricamente), varias veces se pasa y muy pocas veces de menos, el otro es mas uniforme, puede dar 8 o 13.  \n",
    "voy a dejar el otro por ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requests start to arrive\n",
      "The next request will arrive in 9.903289714840097, we are at 0\n",
      "The machine 1 starts.\n",
      "A request arrived and was buffered at time 9.903289714840097\n",
      "The next request will arrive in 11.819796556773825, we are at 9.903289714840097\n",
      "A request is starting to be processed by machine 1 at 9.90399999999995\n",
      "9.903289714840097\n",
      "La cantidad de requests en el buffer es 0\n",
      "Machine 1 will finish at 26.409482858066777\n",
      "A request arrived and was buffered at time 21.723086271613923\n",
      "The next request will arrive in 0.45552905963801965, we are at 21.723086271613923\n",
      "A request arrived and was buffered at time 22.178615331251944\n",
      "The next request will arrive in 2.6730956815281606, we are at 22.178615331251944\n",
      "A request arrived and was buffered at time 24.851711012780104\n",
      "The next request will arrive in 5.052719772173712, we are at 24.851711012780104\n",
      "Machine 1 has finished processing the request at 26.409482858066777\n",
      "A request is starting to be processed by machine 1 at 26.409482858066777\n",
      "21.723086271613923\n",
      "La cantidad de requests en el buffer es 2\n",
      "Machine 1 will finish at 46.109143786023154\n",
      "A request arrived and was buffered at time 29.904430784953817\n",
      "The next request will arrive in 2.5981845794967, we are at 29.904430784953817\n",
      "A request arrived and was buffered at time 32.50261536445052\n",
      "The next request will arrive in 0.6023474366438158, we are at 32.50261536445052\n",
      "A request arrived and was buffered at time 33.10496280109434\n",
      "The next request will arrive in 1.9727708303117677, we are at 33.10496280109434\n",
      "A request arrived and was buffered at time 35.077733631406105\n",
      "The next request will arrive in 0.5877707204322209, we are at 35.077733631406105\n",
      "A request arrived and was buffered at time 35.66550435183832\n",
      "The next request will arrive in 1.261017240335812, we are at 35.66550435183832\n",
      "A request arrived and was buffered at time 36.92652159217413\n",
      "The next request will arrive in 0.053210060712957086, we are at 36.92652159217413\n",
      "A request arrived and was buffered at time 36.97973165288709\n",
      "The next request will arrive in 7.582347211469553, we are at 36.97973165288709\n",
      "A request arrived and was buffered at time 44.56207886435664\n",
      "The next request will arrive in 16.942857600944944, we are at 44.56207886435664\n",
      "Machine 1 has finished processing the request at 46.109143786023154\n",
      "A request is starting to be processed by machine 1 at 46.109143786023154\n",
      "22.178615331251944\n",
      "La cantidad de requests en el buffer es 9\n",
      "Machine 1 will finish at 46.86835888541985\n",
      "Machine 1 has finished processing the request at 46.86835888541985\n",
      "A request is starting to be processed by machine 1 at 46.86835888541985\n",
      "24.851711012780104\n",
      "La cantidad de requests en el buffer es 8\n",
      "Machine 1 will finish at 51.32351835463345\n",
      "Machine 1 has finished processing the request at 51.32351835463345\n",
      "A request is starting to be processed by machine 1 at 51.32351835463345\n",
      "29.904430784953817\n",
      "La cantidad de requests en el buffer es 7\n",
      "Machine 1 will finish at 59.74471797492297\n",
      "Machine 1 has finished processing the request at 59.74471797492297\n",
      "A request is starting to be processed by machine 1 at 59.74471797492297\n",
      "32.50261536445052\n",
      "La cantidad de requests en el buffer es 6\n",
      "Machine 1 will finish at 64.07502560741747\n",
      "A request arrived and was buffered at time 61.50493646530158\n",
      "The next request will arrive in 9.29007017751686, we are at 61.50493646530158\n",
      "Machine 1 has finished processing the request at 64.07502560741747\n",
      "A request is starting to be processed by machine 1 at 64.07502560741747\n",
      "33.10496280109434\n",
      "La cantidad de requests en el buffer es 6\n",
      "Machine 1 will finish at 65.07893800182383\n",
      "Machine 1 has finished processing the request at 65.07893800182383\n",
      "A request is starting to be processed by machine 1 at 65.07893800182383\n",
      "35.077733631406105\n",
      "La cantidad de requests en el buffer es 5\n",
      "Machine 1 will finish at 68.36688938567677\n",
      "Machine 1 has finished processing the request at 68.36688938567677\n",
      "A request is starting to be processed by machine 1 at 68.36688938567677\n",
      "35.66550435183832\n",
      "La cantidad de requests en el buffer es 4\n",
      "Machine 1 will finish at 69.3465072530638\n",
      "Machine 1 has finished processing the request at 69.3465072530638\n",
      "A request is starting to be processed by machine 1 at 69.3465072530638\n",
      "36.92652159217413\n",
      "La cantidad de requests en el buffer es 3\n",
      "Machine 1 will finish at 71.4482026536235\n",
      "A request arrived and was buffered at time 70.79500664281844\n",
      "The next request will arrive in 4.131698752484505, we are at 70.79500664281844\n",
      "Machine 1 has finished processing the request at 71.4482026536235\n",
      "A request is starting to be processed by machine 1 at 71.4482026536235\n",
      "36.97973165288709\n",
      "La cantidad de requests en el buffer es 3\n",
      "Machine 1 will finish at 71.5368860881451\n",
      "Machine 1 has finished processing the request at 71.5368860881451\n",
      "A request is starting to be processed by machine 1 at 71.5368860881451\n",
      "44.56207886435664\n",
      "La cantidad de requests en el buffer es 2\n",
      "Machine 1 will finish at 84.17413144059435\n",
      "A request arrived and was buffered at time 74.92670539530295\n",
      "The next request will arrive in 0.8957778899575117, we are at 74.92670539530295\n",
      "A request arrived and was buffered at time 75.82248328526046\n",
      "The next request will arrive in 13.473266984191824, we are at 75.82248328526046\n",
      "Machine 1 has finished processing the request at 84.17413144059435\n",
      "A request is starting to be processed by machine 1 at 84.17413144059435\n",
      "61.50493646530158\n",
      "La cantidad de requests en el buffer es 3\n",
      "Machine 1 will finish at 112.41222744216925\n",
      "A request arrived and was buffered at time 89.29575026945228\n",
      "The next request will arrive in 3.8235563284359615, we are at 89.29575026945228\n",
      "A request arrived and was buffered at time 93.11930659788824\n",
      "The next request will arrive in 5.629450709290801, we are at 93.11930659788824\n",
      "A request arrived and was buffered at time 98.74875730717903\n",
      "The next request will arrive in 5.916099520323228, we are at 98.74875730717903\n"
     ]
    }
   ],
   "source": [
    "env = simpy.Environment()\n",
    "init = env.now\n",
    "requests_center = simpy.Resource(env, 1)\n",
    "requests_buffer = simpy.Store(env, BUFFER_SIZE)\n",
    "env.process(request_generator(env, requests_center, requests_buffer, int(time.time())))\n",
    "\n",
    "amount = []\n",
    "machine_1 = Machine(1)\n",
    "machine_2 = Machine(2)\n",
    "env.process(buffer_stats(env, requests_buffer, amount))\n",
    "env.process(processing_machine(env, requests_center, requests_buffer, int(time.time()), machine_1))\n",
    "#env.process(processing_machine(env, requests_center, requests_buffer, int(time.time()), machine_2))\n",
    "\n",
    "env.run(until=SIM_TIME)\n",
    "\n",
    "end = env.now"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocupation factor con una maquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocupation_factor: 1.0250822744216928\n",
      "102.50822744216929\n"
     ]
    }
   ],
   "source": [
    "program_time = end - init\n",
    "ocupation_factor = machine_1.working_time/SIM_TIME\n",
    "print(f\"ocupation_factor: {ocupation_factor}\")\n",
    "print(machine_1.working_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocupation factor con dos maquinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocupation_factor: 0.5125411372108464\n"
     ]
    }
   ],
   "source": [
    "ocupation_factor = (machine_1.working_time + machine_2.working_time)/(program_time*2)\n",
    "print(f\"ocupation_factor: {ocupation_factor}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad media de elementos en el buffer: a cada segundo mido la cantidad de elementos en el buffer, luego divido la suma por la cantidad total de mediciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantidad media de elementos en el buffer: 4.07\n"
     ]
    }
   ],
   "source": [
    "cant = 0\n",
    "for i in amount:\n",
    "    cant += i\n",
    "\n",
    "cant = cant/len(amount)\n",
    "print(f\"cantidad media de elementos en el buffer: {cant}\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos la cantidad media de solicitudes en el sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 4, 4, 3, 3, 3, 4, 4, 4, 5, 6, 6, 8, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 6, 5, 5, 5, 4, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "3.64\n"
     ]
    }
   ],
   "source": [
    "total_req_time_stats = machine_1.req_time_stats + machine_2.req_time_stats\n",
    "\n",
    "req_quantity = []\n",
    "for second in range(SIM_TIME):\n",
    "    interval_req_quantity = 0\n",
    "    for time_tup in total_req_time_stats:\n",
    "        finish_time = time_tup[2]\n",
    "        arrival_time = finish_time - time_tup[1] # finish_time - system_time\n",
    "        if arrival_time < second < finish_time:\n",
    "            \"\"\" \n",
    "            If the second we are checking is between the finish time and arrival time\n",
    "            it means that the request was living on the system at that second.\n",
    "            \"\"\"\n",
    "            interval_req_quantity += 1\n",
    "    req_quantity.append(interval_req_quantity)\n",
    "print(req_quantity)\n",
    "print(mean(req_quantity))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gas_station_control' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m env \u001b[39m=\u001b[39m simpy\u001b[39m.\u001b[39mEnvironment()\n\u001b[1;32m      4\u001b[0m processing_center \u001b[39m=\u001b[39m simpy\u001b[39m.\u001b[39mResource(env, \u001b[39m2\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m env\u001b[39m.\u001b[39mprocess(gas_station_control(env, fuel_pump))\n\u001b[1;32m      7\u001b[0m env\u001b[39m.\u001b[39mprocess(car_generator(env, gas_station, fuel_pump))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gas_station_control' is not defined"
     ]
    }
   ],
   "source": [
    "random.seed(22)\n",
    "\n",
    "env = simpy.Environment()\n",
    "processing_center = simpy.Resource(env, 2)\n",
    "\n",
    "env.process(gas_station_control(env, fuel_pump))\n",
    "env.process(car_generator(env, gas_station, fuel_pump))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'Person' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Joaquin\\Desktop\\simulacion\\Los-Simuladores\\tp2.ipynb Cell 36\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/simulacion/Los-Simuladores/tp2.ipynb#X50sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m person2 \u001b[39m=\u001b[39m Person(\u001b[39m\"\u001b[39m\u001b[39mBob\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m30\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/simulacion/Los-Simuladores/tp2.ipynb#X50sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Store instances in the container\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/simulacion/Los-Simuladores/tp2.ipynb#X50sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m people_container\u001b[39m.\u001b[39;49mput(person1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/simulacion/Los-Simuladores/tp2.ipynb#X50sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m people_container\u001b[39m.\u001b[39mput(person2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Joaquin/Desktop/simulacion/Los-Simuladores/tp2.ipynb#X50sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Retrieve instances from the container\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\python\\lib\\site-packages\\simpy\\resources\\container.py:28\u001b[0m, in \u001b[0;36mContainerPut.__init__\u001b[1;34m(self, container, amount)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, container: \u001b[39m'\u001b[39m\u001b[39mContainer\u001b[39m\u001b[39m'\u001b[39m, amount: ContainerAmount):\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mif\u001b[39;00m amount \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m:\n\u001b[0;32m     29\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mamount(=\u001b[39m\u001b[39m{\u001b[39;00mamount\u001b[39m}\u001b[39;00m\u001b[39m) must be > 0.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mamount \u001b[39m=\u001b[39m amount\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'Person' and 'int'"
     ]
    }
   ],
   "source": [
    "import simpy\n",
    "\n",
    "class Person:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "# Create a SimPy environment\n",
    "env = simpy.Environment()\n",
    "\n",
    "# Create a container\n",
    "people_container = simpy.Container(env, init=0)\n",
    "\n",
    "# Create instances of the class\n",
    "person1 = Person(\"Alice\", 25)\n",
    "person2 = Person(\"Bob\", 30)\n",
    "\n",
    "# Store instances in the container\n",
    "people_container.put(person1)\n",
    "people_container.put(person2)\n",
    "\n",
    "# Retrieve instances from the container\n",
    "while people_container.level > 0:\n",
    "    person = people_container.get()\n",
    "    print(person.name)\n",
    "\n",
    "# Output: \"Alice\" followed by \"Bob\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
