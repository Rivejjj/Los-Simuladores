{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grupo 4: Aschieri Juan Pablo, Civini Diego Emanuel, Rivero Joaquin, Rovira Rossel Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e, log\n",
    "import time\n",
    "from heapq import heappush, heappop\n",
    "from scipy.stats import poisson\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import simpy\n",
    "import numpy as np\n",
    "import random\n",
    "from statistics import mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generador de numeros aleatorio del TP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xorshift_generator:\n",
    "    def __init__(self, seed):\n",
    "        self.x = seed\n",
    "        self.y = 463820370\n",
    "        self.z = 138409373\n",
    "        self.w = 12872349\n",
    "\n",
    "    def rand(self):\n",
    "        tmp = ( self.x ^ (self.x << 13) ) \n",
    "        self.x = self.y\n",
    "        self.y = self.z\n",
    "        self.z = self.w\n",
    "        self.w = (self.w^(self.w>>17) ) ^ (tmp^(tmp>>5))\n",
    "        return self.w & 0xffffffff\n",
    "    \n",
    "    def get_n_rand(self, n):\n",
    "        rand_numbers = []\n",
    "        for i in range(n):\n",
    "            rand_numbers.append(self.rand())\n",
    "        return rand_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Uniform_generator:\n",
    "    def __init__(self, seed, scale= 1, displacement= 0):\n",
    "        self.xorshift_genertor = Xorshift_generator(seed)\n",
    "        self.scale = scale\n",
    "        self.displacement = displacement\n",
    "\n",
    "    def rand(self):\n",
    "        n = self.xorshift_genertor.rand() / ((2**32)-1)\n",
    "        return n * self.scale + self.displacement\n",
    "    \n",
    "    def get_n_rand(self, n):\n",
    "        rand_numbers = []\n",
    "        for i in range(n):\n",
    "            rand_numbers.append(self.rand())\n",
    "        return rand_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exp_generator:\n",
    "    def __init__(self, seed, parameter=1):\n",
    "        self.parameter = parameter\n",
    "        self.Uniform_generator = Uniform_generator(seed)\n",
    "\n",
    "    def rand(self):\n",
    "        r = self.Uniform_generator.rand()\n",
    "        if self.parameter >=1:\n",
    "            return log(r/self.parameter) / (-1*self.parameter)\n",
    "        else: \n",
    "            return -log(1 - r) / self.parameter\n",
    "\n",
    "    def get_n_rand(self, n):\n",
    "        rand_numbers = []\n",
    "        for i in range(n):\n",
    "            rand_numbers.append(self.rand())\n",
    "        return rand_numbers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descubri que los primeros dos numeros del generador son muy distintos y despues se acomoda. lo de abajo hay que borrarlo  \n",
    "tambien sospecho que por lo general da media menor que 6 mas seguido que mayor que 6, creo que tienee sentido pero mmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = int(time.time())\n",
    "\n",
    "exp_generator = Exp_generator(seed, 1/6)\n",
    "\n",
    "b = exp_generator.rand()\n",
    "b = exp_generator.rand()\n",
    "a = []\n",
    "\n",
    "for i in range(100):\n",
    "    n = exp_generator.rand()\n",
    "    a.append(n)\n",
    "    if n < 0:\n",
    "        print(n)\n",
    "\n",
    "print(a)\n",
    "print(sum(a)/len(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un generador de una distribucion de poisson porque lo utilizaremos mas adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    resultado = 1\n",
    "    for i in range(1, n + 1):\n",
    "        resultado *= i\n",
    "    return resultado\n",
    "\n",
    "def poisson_probability(parameter, i, previous_probability):\n",
    "    if previous_probability == 0:\n",
    "        return poisson.pmf(i, parameter)\n",
    "    return (parameter/i)*previous_probability\n",
    "\n",
    "class Poisson_generator:\n",
    "    def __init__(self, seed, parameter):\n",
    "        self.parameter = parameter\n",
    "        self.Uniform_generator = Uniform_generator(seed)\n",
    "\n",
    "    def rand(self):\n",
    "        r = self.Uniform_generator.rand()\n",
    "\n",
    "        accumulated_probability = poisson_probability(self.parameter, 0, 0)\n",
    "        previous_probability = accumulated_probability\n",
    "        i = 0\n",
    "\n",
    "        while(accumulated_probability < r):\n",
    "            i += 1\n",
    "            previous_probability = poisson_probability(self.parameter, i, previous_probability)\n",
    "            accumulated_probability += previous_probability\n",
    "\n",
    "        return i\n",
    "    \n",
    "    def get_n_rand(self, n):\n",
    "        rand_numbers = []\n",
    "        for i in range(n):\n",
    "            rand_numbers.append(self.rand())\n",
    "        return rand_numbers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumimos que el satÃ©lite da siempre la misma vuelta al mundo que tarda lo mismo, y que se puede pensar al tiempo en que tarda el satelite en llegar a una posicion a la que puede sacar una foto de la request como una uniforme entre 0 y el tiempo en que tarda en dar la vuelta al mundo, ya que los puntos sobre el globo se distribuyen uniformemente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simular el problema lo que hacemos es definir un delta de tiempo (time step), que sera de cada que intervalo discreto avanzaremos el tiempo de la simulacion. Por cada iteracion generamos un valor de una distribucion de poisson que representa la cantidad de arribos de solicitudes que llegaron en el ultimo intervalo de tiempo. Por cada solicitud de tiempo que halla llegado luego generamos un valor de tiempo con una distribucion uniforme entre 0 y el satelite_perior (tiempo en dar la vuelta al mundo del satelite), que representa el tiempo que tardara el satelite en estar en posicion para poder sacar la foto. Por cada iteracion avanzamos el tiempo de todas las request en la cola, y agregamos las nuevas, ademas de ir anotando datos como cuantas veces hubo cada longitud de cola en todas las iteraciones, y cuanto fue el tiempo para servir a la primera request para cada longitud de cola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_satelite_request_queue_length(time_step, iterations, request_per_unit_time, satelite_period):\n",
    "    generator_amount_of_request = Poisson_generator(int(time.time()) * 8647359734, request_per_unit_time*time_step)\n",
    "    generator_time_to_serve = Uniform_generator(int(time.time()) * 345678976, satelite_period)\n",
    "    simulated_queue = []\n",
    "    observed_queue_length = {}\n",
    "    time_to_serve_first_for_queue_length = {}\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        advance_time(simulated_queue, time_step)\n",
    "        get_acumulated_requests(generator_amount_of_request, simulated_queue, generator_time_to_serve)    \n",
    "        observed_queue_length[len(simulated_queue)] = observed_queue_length.get(len(simulated_queue), 0) + 1\n",
    "        if len(simulated_queue) != 0:\n",
    "            time_to_serve_first_for_queue_length.setdefault(len(simulated_queue), []).append(simulated_queue[0])\n",
    "            \n",
    "    return get_frequencies(observed_queue_length, iterations), get_mean_times(time_to_serve_first_for_queue_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advance_time(simulated_queue, time_step):\n",
    "    for i in range(len(simulated_queue)):\n",
    "        simulated_queue[i] -= time_step\n",
    "\n",
    "    while (len(simulated_queue) != 0 and simulated_queue[0] <= 0):\n",
    "        item = heappop(simulated_queue)\n",
    "        #print(f'Se elimino una request de tiempo: {item}')\n",
    "\n",
    "def get_acumulated_requests(generator_amount_of_request, simulated_queue, generator_time_to_serve):\n",
    "    amount_of_requests = generator_amount_of_request.rand()\n",
    "    for request in range(amount_of_requests):\n",
    "        #por ahora asumimos que el time to serve es uniforme, porque se hacen requests uniformemente alrededor del mundo\n",
    "        heappush(simulated_queue, generator_time_to_serve.rand())\n",
    "\n",
    "def get_frequencies(observed_queue_length, iterations):\n",
    "    #print(f'Entro a get_frequencies con dicc = {observed_queue_length}')\n",
    "    observed_frequencies = []\n",
    "    #print(f'El maximo es: {max(observed_queue_length.keys())}')\n",
    "    for j in range(max(observed_queue_length.keys()) + 1):\n",
    "        times_observed = observed_queue_length.get(j, 0)\n",
    "        #print(f'Para {j} se observo {times_observed}')\n",
    "        observed_frequencies.append(times_observed/iterations)\n",
    "    return observed_frequencies\n",
    "\n",
    "def get_mean_times(time_to_serve_for_queue_length):\n",
    "    mean_times = {}\n",
    "\n",
    "    for key in time_to_serve_for_queue_length:\n",
    "        sum_of_times = 0\n",
    "        for j in time_to_serve_for_queue_length[key]:\n",
    "            sum_of_times += j\n",
    "        mean_times[key] = sum_of_times/len(time_to_serve_for_queue_length[key])\n",
    "    \n",
    "    return mean_times"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulamos un ejemplo donde tomamos que el satelite tarde 48 horas en dar la vuelta al mundo, y que llegan 10 requests por dia en promedio. Usamos un intervalo de media hora y realizamos 50 000 horas de simulacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies, times = simulate_satelite_request_queue_length(0.5, 100000, 5/12, 48)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que como en general se acumulan las request hasta llegar al rededor de 10 y luego tiende a disminuir la cantidad que hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = list(range(len(frequencies)))\n",
    "y_axis = frequencies\n",
    "plt.plot(x_axis, y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paper llegaba a la conclusion de que cuantas mas solicitudes hayan en la cola, el tiempo que se tarda en servir estas request es menor. Para verificar esto miramos el siguiente grafico que muestra el tiempo promedio que tarda el satelite en servir al request mas cercano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(times.keys(), times.values())\n",
    "plt.xlabel(\"Queue length\")\n",
    "plt.ylabel(\"Avarege time to serve first request\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que en este caso asi sucede, cuantas mas solicitudes hay en la cola menor es el tiempo para tomar la foto. Esto tiene sentido ya que cuantas mas request hayan en espera mas chances habra de que haya alguna mas cercana.\n",
    "Si bien el grafico solo muestra la primera requet, como esto se modela como un proceso de poisson, por propiedad de perdidad de memoria se puede ver que se cumplira para el tiempo entre todos los arribos. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 100\n",
    "SIM_TIME = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Factor de ocupaciÃ³n del sistema. (listo)\n",
    "- Cantidad media de solicitudes en el buffer (listo)\n",
    "- Cantidad media de solicitudes en el sistema (listo)\n",
    "- Tiempo medio que las solicitudes estÃ¡n en el buffer (listo)\n",
    "- Tiempo medio de solicitudes en el sistema (listo)\n",
    "- Determinar el tamaÃ±a del buffer para que la probabilidad de que haya lugar para recibir solicitudes sea\n",
    "como mucho 3%.\n",
    "- Evaluar la posibilidad de reemplazar las dos mÃ¡quinas por una sola que procesa todos las solicitudes en\n",
    "un tiempo fijo de 5 segundos. Si el costo de tener solicitudes en el buffer es 0,2 USD/minuto y el costo\n",
    "de modificar la mÃ¡quina es 2000 USD, CuÃ¡nto tiempo tomarÃ¡ amortizar el inversiÃ³n?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta manera cada maquina es un proceso y desp hay otro proceso que se encarga de llenar las lista con requests para que cada maquina vaya desencolando \n",
    "y procesando requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    \n",
    "    def __init__(self,id):\n",
    "        self.working_time = 0\n",
    "        self.requests_taken = 0\n",
    "        self.id = id\n",
    "        self.req_time_stats = []\n",
    "    \n",
    "    def process_request(self, request):\n",
    "        self.requests_taken += 1\n",
    "        self.working_time += request\n",
    "\n",
    "    def add_req_time_stat(self, time_tup):\n",
    "        # The tuple has the following format: (req_buffer_time, req_system_time, req_finish_time)\n",
    "        self.req_time_stats.append(time_tup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Con esta implementacion, las maquinas chequean que haya requests en la cola cada 1 seg. Osea, que si la cola estaa vacia, la maquina cada 1 seg va a \n",
    "chequear si llego un nuevo mensaje. Ver con los chicos si estan de acuerdo con esto (o tamb preguntar al de la practica). Porque otro caso que CREO que se puede\n",
    "hacer es que apenas llegue un request, la maquina ya sepa y lo empieze a procesar all instante.\n",
    "Tambien ver que onda el arrribo de mensajes, estan llegando cada mucho tiempo y los procesa re rapido entonces la cola siempre esta vacia\n",
    "\"\"\"\n",
    "def request_generator(env, requests_center, requests_buffer, seed):\n",
    "    \"\"\"Las solicitudes llegan siguiendo un proceso Poisson con una frecuencia media de 10\n",
    "    por minuto. Por ende el tiempo entre 2 solicitudes consecutivas seguira una distribucion\n",
    "    Exponencial de paremtro 10.\"\"\"\n",
    "    exponential_gen = Exp_generator(seed, 1/6) \n",
    "    \n",
    "    print(\"Requests start to arrive\")\n",
    "    for i in itertools.count():\n",
    "        time_for_next_request = exponential_gen.rand()\n",
    "        #time_for_next_request = np.random.exponential(6) # El parametro en esta lib tiene que ser b=1/lambda\n",
    "\n",
    "        print(f\"The next request will arrive in {time_for_next_request}, we are at {env.now}\")\n",
    "        yield env.timeout(time_for_next_request)\n",
    "        with requests_center.request() as req:\n",
    "            yield req\n",
    "            if len(requests_buffer.items) == BUFFER_SIZE:\n",
    "                print(f\"The buffer is full and cannot accept more requests. This requests has been dropped at time {env.now}\")\n",
    "            else:\n",
    "                print(f\"A request arrived and was buffered at time {env.now}\")\n",
    "                yield requests_buffer.put(env.now)\n",
    "    print(\"Requests will stop to arrive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_machine(env, requests_center, requests_buffer, seed, machine):\n",
    "    exponential_gen = Exp_generator(seed, 1/10)\n",
    "    print(f\"The machine {machine.id} starts.\")\n",
    "    while True:\n",
    "        \n",
    "        time_to_process = 0.001\n",
    "        request_processed = False\n",
    "        #print(f\"Machine {machine.id} will try to process a request at {env.now}\")\n",
    "        with requests_center.request() as req:\n",
    "            yield req\n",
    "            \n",
    "            if len(requests_buffer.items) != 0:\n",
    "                print(f\"A request is starting to be processed by machine {machine.id} at {env.now}\")\n",
    "                arrival_time = yield requests_buffer.get()\n",
    "                print(arrival_time)\n",
    "                buffer_time = env.now - arrival_time\n",
    "                print(f\"La cantidad de requests en el buffer es {len(requests_buffer.items)}\")\n",
    "                time_to_process = exponential_gen.rand()\n",
    "                #time_to_process = np.random.exponential(10)\n",
    "                machine.process_request(time_to_process)\n",
    "                print(f\"Machine {machine.id} will finish at {time_to_process + env.now}\")\n",
    "                request_processed = True\n",
    "                \n",
    "        # If there are no requests to process in the buffer, the timeout is of 0 seconds.\n",
    "        yield env.timeout(time_to_process)\n",
    "        if request_processed:\n",
    "            system_time = env.now - arrival_time\n",
    "            finish_time = arrival_time + system_time\n",
    "            time_tup = (buffer_time, system_time, finish_time)\n",
    "            machine.add_req_time_stat(time_tup)\n",
    "            print(f\"Machine {machine.id} has finished processing the request at {env.now}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer_stats(env, buffer, amount):\n",
    "    while True:\n",
    "        amount.append(len(buffer.items))\n",
    "        yield env.timeout(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos usar nuestro generador, ronda cantidad de llegadas 11/12 en el primer minuto (empiricamente), varias veces se pasa y muy pocas veces de menos, el otro es mas uniforme, puede dar 8 o 13.  \n",
    "voy a dejar el otro por ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simpy.Environment()\n",
    "init = env.now\n",
    "requests_center = simpy.Resource(env, 1)\n",
    "requests_buffer = simpy.Store(env, BUFFER_SIZE)\n",
    "env.process(request_generator(env, requests_center, requests_buffer, int(time.time())))\n",
    "\n",
    "amount = []\n",
    "machine_1 = Machine(1)\n",
    "machine_2 = Machine(2)\n",
    "env.process(buffer_stats(env, requests_buffer, amount))\n",
    "env.process(processing_machine(env, requests_center, requests_buffer, int(time.time()), machine_1))\n",
    "#env.process(processing_machine(env, requests_center, requests_buffer, int(time.time()), machine_2))\n",
    "\n",
    "env.run(until=SIM_TIME)\n",
    "\n",
    "end = env.now"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocupation factor con una maquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_time = end - init\n",
    "ocupation_factor = machine_1.working_time/SIM_TIME\n",
    "print(f\"ocupation_factor: {ocupation_factor}\")\n",
    "print(machine_1.working_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocupation factor con dos maquinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocupation_factor = (machine_1.working_time + machine_2.working_time)/(program_time*2)\n",
    "print(f\"ocupation_factor: {ocupation_factor}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad media de elementos en el buffer: a cada segundo mido la cantidad de elementos en el buffer, luego divido la suma por la cantidad total de mediciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant = 0\n",
    "for i in amount:\n",
    "    cant += i\n",
    "\n",
    "cant = cant/len(amount)\n",
    "print(f\"cantidad media de elementos en el buffer: {cant}\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos la cantidad media de solicitudes en el sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_req_time_stats = machine_1.req_time_stats + machine_2.req_time_stats\n",
    "\n",
    "req_quantity = []\n",
    "for second in range(SIM_TIME):\n",
    "    interval_req_quantity = 0\n",
    "    for time_tup in total_req_time_stats:\n",
    "        finish_time = time_tup[2]\n",
    "        arrival_time = finish_time - time_tup[1] # finish_time - system_time\n",
    "        if arrival_time < second < finish_time:\n",
    "            \"\"\" \n",
    "            If the second we are checking is between the finish time and arrival time\n",
    "            it means that the request was living on the system at that second.\n",
    "            \"\"\"\n",
    "            interval_req_quantity += 1\n",
    "    req_quantity.append(interval_req_quantity)\n",
    "print(req_quantity)\n",
    "print(mean(req_quantity))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Truck:\n",
    "\n",
    "    def __init__(self, env, id, arrival_time):\n",
    "        self.env = env\n",
    "        self.id = id\n",
    "        self.arrival_time = arrival_time\n",
    "        self.download_shipment_time = None\n",
    "        self.finish_time = None\n",
    "\n",
    "\n",
    "    def download_shipment(self, distribution_center, type):\n",
    "        exp_generator = Exp_generator(int(env.now), 1/5)\n",
    "        if type == 'barcode':\n",
    "            exp_generator = Exp_generator(int(env.now), 1/30)\n",
    "\n",
    "        n1 = exp_generator.rand() # TO-DO: Ver porq nuestro generados los primeros numero son chiquitos\n",
    "        n2 = exp_generator.rand()\n",
    "        with distribution_center.request() as req:\n",
    "            yield req\n",
    "            self.download_shipment_time = env.now\n",
    "            time_to_download = exp_generator.rand()\n",
    "            print(f'The truck {self.id} started to download the shipment at {env.now}, it will finish at {env.now + time_to_download}')\n",
    "            yield env.timeout(time_to_download)\n",
    "        self.finish_time = env.now\n",
    "        print(f'The truck {self.id} finished at {env.now}')\n",
    "            \n",
    "\n",
    "def truck_generator(env, distribution_center, seed, trucks, type):\n",
    "    exp_generator = Exp_generator(seed, 1/12)\n",
    "    for i in itertools.count():\n",
    "        time_for_next_truck = exp_generator.rand()\n",
    "        print(f'The next truck will arrive in {time_for_next_truck}')\n",
    "        yield env.timeout(time_for_next_truck)\n",
    "        print(f'The truck {i} arrived at {env.now}')\n",
    "        truck = Truck(env, i, env.now)\n",
    "        env.process(truck.download_shipment(distribution_center, type))\n",
    "        trucks.append(truck)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escenario en el que se usa codigo de barras para descargar y hay 4 darsenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next truck will arrive in 1.1757733802229244\n",
      "The truck 0 arrived at 1.1757733802229244\n",
      "The next truck will arrive in 30.721401857562935\n",
      "The truck 0 started to download the shipment at 1.1757733802229244, it will finish at 60.6026430556568\n",
      "The truck 1 arrived at 31.89717523778586\n",
      "The next truck will arrive in 12.560618941798008\n",
      "The truck 1 started to download the shipment at 31.89717523778586, it will finish at 91.31302737728089\n",
      "The truck 2 arrived at 44.45779417958387\n",
      "The next truck will arrive in 0.09194971514311881\n",
      "The truck 2 started to download the shipment at 44.45779417958387, it will finish at 103.86638015741738\n",
      "The truck 3 arrived at 44.54974389472699\n",
      "The next truck will arrive in 9.717763337248192\n",
      "The truck 3 started to download the shipment at 44.54974389472699, it will finish at 103.95832987256048\n",
      "The truck 4 arrived at 54.26750723197518\n",
      "The next truck will arrive in 6.37561387805069\n",
      "The truck 0 finished at 60.6026430556568\n",
      "The truck 4 started to download the shipment at 60.6026430556568, it will finish at 120.00866380086299\n",
      "The truck 5 arrived at 60.643121110025874\n",
      "The next truck will arrive in 35.14703644039693\n",
      "The truck 1 finished at 91.31302737728089\n",
      "The truck 5 started to download the shipment at 91.31302737728089, it will finish at 150.7147732221531\n",
      "The truck 6 arrived at 95.7901575504228\n",
      "The next truck will arrive in 1.2997434384897406\n",
      "The truck 7 arrived at 97.08990098891255\n",
      "The next truck will arrive in 19.885088549746868\n",
      "The truck 2 finished at 103.86638015741738\n",
      "The truck 6 started to download the shipment at 103.86638015741738, it will finish at 163.25487439404924\n",
      "The truck 3 finished at 103.95832987256048\n",
      "The truck 7 started to download the shipment at 103.95832987256048, it will finish at 163.34664594958028\n",
      "The truck 8 arrived at 116.97498953865941\n",
      "The next truck will arrive in 46.04760055326364\n",
      "The truck 4 finished at 120.00866380086299\n",
      "The truck 8 started to download the shipment at 120.00866380086299, it will finish at 179.38813810847054\n",
      "The truck 5 finished at 150.7147732221531\n",
      "The truck 9 arrived at 163.02259009192306\n",
      "The next truck will arrive in 28.77396900349046\n",
      "The truck 9 started to download the shipment at 163.02259009192306, it will finish at 222.48892601193995\n",
      "The truck 6 finished at 163.25487439404924\n",
      "The truck 7 finished at 163.34664594958028\n",
      "The truck 8 finished at 179.38813810847054\n",
      "The truck 10 arrived at 191.79655909541353\n",
      "The next truck will arrive in 29.680500852555667\n",
      "The truck 10 started to download the shipment at 191.79655909541353, it will finish at 251.25432862080143\n",
      "The truck 11 arrived at 221.4770599479692\n",
      "The next truck will arrive in 28.28584894241752\n",
      "The truck 11 started to download the shipment at 221.4770599479692, it will finish at 280.92109919583015\n",
      "The truck 9 finished at 222.48892601193995\n",
      "The truck 12 arrived at 249.7629088903867\n",
      "The next truck will arrive in 26.51294918170845\n",
      "The truck 12 started to download the shipment at 249.7629088903867, it will finish at 309.192374699696\n",
      "The truck 10 finished at 251.25432862080143\n",
      "The truck 13 arrived at 276.27585807209516\n",
      "The next truck will arrive in 11.99176951710216\n",
      "The truck 13 started to download the shipment at 276.27585807209516, it will finish at 335.585410759936\n",
      "The truck 11 finished at 280.92109919583015\n",
      "The truck 14 arrived at 288.26762758919733\n",
      "The next truck will arrive in 7.39312865436814\n",
      "The truck 14 started to download the shipment at 288.26762758919733, it will finish at 347.57196693654515\n",
      "The truck 15 arrived at 295.66075624356546\n",
      "The next truck will arrive in 0.08783187589979392\n",
      "The truck 15 started to download the shipment at 295.66075624356546, it will finish at 354.96477269629804\n",
      "The truck 16 arrived at 295.74858811946524\n",
      "The next truck will arrive in 9.933696825761086\n",
      "The truck 17 arrived at 305.68228494522634\n",
      "The next truck will arrive in 7.839504836229949\n",
      "The truck 12 finished at 309.192374699696\n",
      "The truck 16 started to download the shipment at 309.192374699696, it will finish at 368.4963911524286\n",
      "The truck 18 arrived at 313.5217897814563\n",
      "The next truck will arrive in 24.14577515799348\n",
      "The truck 13 finished at 335.585410759936\n",
      "The truck 17 started to download the shipment at 335.585410759936, it will finish at 394.8833595783774\n",
      "The truck 19 arrived at 337.66756493944973\n",
      "The next truck will arrive in 8.84279020141661\n",
      "The truck 20 arrived at 346.51035514086635\n",
      "The next truck will arrive in 31.989316975546014\n",
      "The truck 14 finished at 347.57196693654515\n",
      "The truck 18 started to download the shipment at 347.57196693654515, it will finish at 406.8731172782806\n",
      "The truck 15 finished at 354.96477269629804\n",
      "The truck 19 started to download the shipment at 354.96477269629804, it will finish at 414.2499157628573\n",
      "The truck 16 finished at 368.4963911524286\n",
      "The truck 20 started to download the shipment at 368.4963911524286, it will finish at 427.7843342368174\n",
      "The truck 21 arrived at 378.49967211641234\n",
      "The next truck will arrive in 9.243564225359899\n",
      "The truck 22 arrived at 387.7432363417722\n",
      "The next truck will arrive in 17.065859163155146\n",
      "The truck 17 finished at 394.8833595783774\n",
      "The truck 21 started to download the shipment at 394.8833595783774, it will finish at 454.157682115708\n",
      "The truck 23 arrived at 404.80909550492737\n",
      "The next truck will arrive in 1.4278731545124483\n",
      "The truck 24 arrived at 406.2369686594398\n",
      "The next truck will arrive in 11.79176976575257\n",
      "The truck 18 finished at 406.8731172782806\n",
      "The truck 22 started to download the shipment at 406.8731172782806, it will finish at 466.24284326267406\n",
      "The truck 19 finished at 414.2499157628573\n",
      "The truck 23 started to download the shipment at 414.2499157628573, it will finish at 473.6140652420079\n",
      "The truck 25 arrived at 418.0287384251924\n",
      "The next truck will arrive in 49.720850647591284\n",
      "The truck 20 finished at 427.7843342368174\n",
      "The truck 24 started to download the shipment at 427.7843342368174, it will finish at 487.14933757654893\n",
      "The truck 21 finished at 454.157682115708\n",
      "The truck 25 started to download the shipment at 454.157682115708, it will finish at 513.5141512266302\n",
      "The truck 22 finished at 466.24284326267406\n",
      "The truck 26 arrived at 467.7495890727837\n",
      "The next truck will arrive in 10.937784629868188\n",
      "The truck 26 started to download the shipment at 467.7495890727837, it will finish at 527.0851741037826\n",
      "The truck 23 finished at 473.6140652420079\n",
      "The truck 27 arrived at 478.6873737026519\n",
      "The next truck will arrive in 2.674446695756484\n",
      "The truck 27 started to download the shipment at 478.6873737026519, it will finish at 538.028271217307\n",
      "The truck 28 arrived at 481.3618203984084\n",
      "The next truck will arrive in 12.525803799913009\n",
      "The truck 24 finished at 487.14933757654893\n",
      "The truck 28 started to download the shipment at 487.14933757654893, it will finish at 546.4797303817722\n",
      "The truck 29 arrived at 493.8876241983214\n",
      "The next truck will arrive in 8.586608089486967\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(22)\n",
    "env = simpy.Environment()\n",
    "distribution_center = simpy.Resource(env, 4)\n",
    "\n",
    "trucks = []\n",
    "env.process(truck_generator(env, distribution_center, int(time.time()) * 235462324, trucks, 'barcode'))\n",
    "\n",
    "env.run(500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EstadÃ­sticas:\n",
    "-  Simular ambos escenarios utilizando Simpy o programaciÃ³n tradicional.\n",
    "-  Cantidad media de camiones en el sistema (listo)\n",
    "-  Cantidad media de camiones en cola (listo)\n",
    "-  Tiempo medio de camiones en el sistema (listo)\n",
    "-  Tiempo medio de camiones en cola (listo)\n",
    "-  QuÃ© recomendaciÃ³n se puede hacer sobre el cierre de la dÃ¡rsena propuesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.89417289891588\n",
      "9.526618215840141\n"
     ]
    }
   ],
   "source": [
    "# We cheack for every second how many trucks were in the system, buffer, their times, etc.\n",
    "system_quantity = []\n",
    "buffer_quantity = []\n",
    "trucks_time_stats = []\n",
    "for second in range(500):\n",
    "    trucks_in_system = 0\n",
    "    trucks_in_buffer = 0\n",
    "    for truck in trucks:\n",
    "        if not all([truck.download_shipment_time,truck.finish_time]):\n",
    "            # If the truck neever got out of the buffer or system beefore the simulation ended, their times cannot be taken into account\n",
    "            continue\n",
    "\n",
    "        if truck.arrival_time < second < truck.finish_time:\n",
    "            trucks_in_system += 1\n",
    "\n",
    "        if truck.arrival_time < second < truck.download_shipment_time:\n",
    "            trucks_in_buffer += 1\n",
    "    system_quantity.append(trucks_in_system)\n",
    "    buffer_quantity.append(trucks_in_buffer)\n",
    "\n",
    "trucks_system_time = [truck.finish_time - truck.arrival_time for truck in trucks if all([truck.download_shipment_time,truck.finish_time])]\n",
    "trucks_buffer_time = [truck.download_shipment_time - truck.arrival_time for truck in trucks if all([truck.download_shipment_time,truck.finish_time])]\n",
    "\n",
    "print(mean(trucks_system_time))\n",
    "print(mean(trucks_buffer_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escenario en el que se usa RFID para descargar y hay 3 darsenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(22)\n",
    "\n",
    "env = simpy.Environment()\n",
    "distribution_center = simpy.Resource(env, 3)\n",
    "\n",
    "trucks = []\n",
    "env.process(truck_generator(env, distribution_center, int(time.time()), trucks, 'rfid'))\n",
    "\n",
    "env.run(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
